{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "zeeGjkrYvBas",
        "khCsa8t2yrl_",
        "D3LlCooLJu06",
        "thuz5aubJ1AZ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flavio-mota/sin260-am/blob/main/Aprendizado_de_M%C3%A1quina.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SIN260 - Sistemas Inteligentes\n",
        "## Aprendizado de Máquina\n",
        "\n",
        "Isabela Neves Drummond\n",
        "<br>Flávio Belizário S. Mota\n",
        "<hr>\n",
        "\n",
        "O objetivo deste notebook jupyter é empregar alguns algoritmos de Aprendizado de Máquina em tarefas de classificação (aprendizado supervisionado) e agrupamento (aprendizado não supervisionado)."
      ],
      "metadata": {
        "id": "Ecp0I07QusgJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ajustando o ambiente"
      ],
      "metadata": {
        "id": "obSUnp_4J3QS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos precisar atualizar uma das bibliotecas do colab para exibir os gráficos (pode ser necessário reiniciar o ambiente):"
      ],
      "metadata": {
        "id": "z0dR5AhbJ6DE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlxtend --upgrade"
      ],
      "metadata": {
        "id": "6dDYQvhmI_E4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## O conjunto de dados"
      ],
      "metadata": {
        "id": "4DAsGjIrwOu6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nos exemplos dessa aula, empregaremos o conjunto de dados Iris. Este é um conjunto de dados famoso que contêm medidas de comprimento e largura das sépalas e pétalas de 150 flores de íris de três espécies diferentes: íris-Setosa, Íris-Versicolor e Íris-Virginica. Existem 50 amostras para cada uma das espécies.  "
      ],
      "metadata": {
        "id": "NTOWs2pPwSq0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><a href=\"https://commons.wikimedia.org/wiki/File:Flores_de_%C3%8Dris.png#/media/Ficheiro:Flores_de_Íris.png\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/c/cb/Flores_de_%C3%8Dris.png\" alt=\"Flores de Íris.png\" width=\"640\" height=\"321\"></a>\n",
        "<br> Por <a href=\"//commons.wikimedia.org/wiki/User:Dcbmariano\" title=\"User:Dcbmariano\"&gt;Diego Mariano&lt;/a&gt; - &lt;span class=\"int-own-work\" lang=\"pt\"&gt;Obra do próprio&lt;/span&gt;, <a href=\"https://creativecommons.org/licenses/by-sa/4.0\" title=\"Creative Commons Attribution-Share Alike 4.0\">CC BY-SA 4.0</a>, <a href=\"https://commons.wikimedia.org/w/index.php?curid=114511020\">Wikipedia</a></p>"
      ],
      "metadata": {
        "id": "Ain8e-7Ew4UV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos importar o conjunto de dados por utilizando o repositório da UCI, que é um grande repositório de conjuntos de dados que podem ser empregados no aprendizado de máquina.\n",
        "\n",
        "[UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)"
      ],
      "metadata": {
        "id": "jmpAFvPazJb7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importando o conjunto de dados"
      ],
      "metadata": {
        "id": "JzZmbVtm13-o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizaremos a biblioteca pandas para carregar os dados do conjunto Iris. Em seguida, vamos exibir os 5 primeiros registros desse conjunto:"
      ],
      "metadata": {
        "id": "DmMU1Jbz165j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uH2vegIuiuK"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\", header=None)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cada registro desse conjunto corresponde a uma flor. Os atributos das colunas 0 e 1 são as medidas de comprimento e largura da sépala. Os atributos 2 e 3 representam o comprimento e largura da pétala. Por fim, o atributo 4 representa a espécie da flor, ou seja, as classes do nosso problema.\n",
        "\n",
        "Para melhorar a leitura desses dados, vamos renomear essas colunas:"
      ],
      "metadata": {
        "id": "jZ2bogan2eoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns = {0:'comprimento_sepala', \n",
        "                     1:'largura_sepala', \n",
        "                     2:'comprimento_petala', \n",
        "                     3:'largura_petala',\n",
        "                     4:'classe'}, inplace = True)\n",
        "df"
      ],
      "metadata": {
        "id": "Z9wMyYeW2ebF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos gerar um gráfico de dispersão para visualizar como esses atributos estão relacionados (ou não):"
      ],
      "metadata": {
        "id": "7DPLcYNk4LHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.set()\n",
        "sns.pairplot(df[['comprimento_sepala', \n",
        "                 'largura_sepala', \n",
        "                 'comprimento_petala', \n",
        "                 'largura_petala', \n",
        "                 'classe']],\n",
        "             hue=\"classe\", diag_kind=\"kde\")"
      ],
      "metadata": {
        "id": "4VNMvlw21OnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Através dos gráficos de dispersão, podemos perceber que algumas combinações de atributos resultam em distribuições onde é mais fácil encontrar as divisões entre as classes. \n",
        "\n",
        "Na maioria das combinações, a classe Iris-setosa é a que se separa mais facilmente das outras duas classes. Iris-versicolor e Iris-virginica têm valores que se sobrepõem independente da combinação de atributos. Isso nos diz que essas duas classes serão mais dificeis de separar do que a classe Iris-setosa.\n",
        "\n",
        "O conjunto é formado por 4 atributos. Isso significa que nosso problema está distribuido espacialmente em 4 dimensões... Visualizar isso, para nós que somos seres contidos em um espaço de 3 dimensões, exige certa abstração que dificulta entender como separar as classes do problema. Sendo assim, por uma facilidade (e para que a aula fique mais interessante), vamos considerar apenas 2 atributos do conjunto, nesse caso a lagura e comprimento da pétala."
      ],
      "metadata": {
        "id": "Nzt6-kKD-7cd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criando um modelo de classificação"
      ],
      "metadata": {
        "id": "h4Q--Jl2CX1I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definidos os atributos que serão empregados, vamos criar nosso modelo de classificação. Nessa aula, iremos utilizar o Naïve Bayes. Esse é um modelo relativamente simples que não necessita de tantos parâmetros de configuração para funcionar."
      ],
      "metadata": {
        "id": "Osg_PNdBCdM0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparando o conjunto"
      ],
      "metadata": {
        "id": "hLgHwkoOFlDy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por se tratar de um problema de aprendizado supervisionado, o objetivo é a identificação de uma classe previamente informada. Sendo assim, iremos dividir nosso conjunto entre as amostras, que chamaremos de X, e os rótulos, que chamaremos de y:"
      ],
      "metadata": {
        "id": "3BpLD2g0FoDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['comprimento_petala', \n",
        "        'largura_petala']]\n",
        "y = df['classe']\n",
        "print(\"Variável X:\", X)\n",
        "print(\"Classes (y):\", y)"
      ],
      "metadata": {
        "id": "ZvC2wm0J6lpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora temos a variável X que armazena nossos 2 atributos e a variável y com os valores das respectivas classes.\n",
        "\n",
        "A variável y armazena os valores das classes no formato textual. Entretanto, algoritmos de aprendizado de máquina são modelos computacionais que manipulam informações numéricas. Dessa forma, precisamos realizar a codificação dos valores textuais para valores numéricos:"
      ],
      "metadata": {
        "id": "TpwZTnfPKDKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "y"
      ],
      "metadata": {
        "id": "CKfqSBH6JwRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após a transformação, as classes Iris-setosa, Iris-versicolor e Iris-virginica são representadas pelos valores 0, 1 e 2, respectivamente."
      ],
      "metadata": {
        "id": "PFqcc63zQYzm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separando o conjunto"
      ],
      "metadata": {
        "id": "y_nV6yIQRWUP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora, iremos separar nosso conjunto em amostras de treinamento e teste. Essa etapa é importante para que seja possível validar se o modelo gerado é capaz de executar bem a classificação dos dados."
      ],
      "metadata": {
        "id": "BTQuAp07RZCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, train_size=0.8, random_state=42)"
      ],
      "metadata": {
        "id": "9CJqHqWXQNi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A função executada gera uma divisão na qual 80% do conjunto compõe as amostras de treinamento e 20% as amostras de teste."
      ],
      "metadata": {
        "id": "ucZpY5y9Sh66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Quantidade de amostras de treinamento:\", X_treino.shape[0])\n",
        "print(\"Quantidade de amostras de teste:\", X_teste.shape[0])"
      ],
      "metadata": {
        "id": "Em4r8IRDSPk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treinando e avaliando o modelo"
      ],
      "metadata": {
        "id": "lwNn2ciKT_eu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos agora treinar um modelo de classificação que permita identificar as classes do nosso problema.\n",
        "\n",
        "Utilizaremos o algoritmo Naïve Bayes. Podemos treinar o modelo, utilizando a biblioteca sklearn, através do método fit(), que espera as amostras do conjunto de treinamento com seus respectivos rótulos. Em seguida, vamos utilizar o método score() que quantifica o acerto do modelo na fase de treinamento:   "
      ],
      "metadata": {
        "id": "pkk8qXniUFq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_treino.values, y_treino)\n",
        "nb.score(X_treino.values, y_treino)"
      ],
      "metadata": {
        "id": "6Fv_jO4ZSfCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esse valor indica que o modelo é capaz de encontrar corretamente a classe para 95% das amostras do conjunto de treinamento.\n",
        "\n",
        "Depois da etapa de treinamento, podemos utilizar o modelo para prever os valores de classe para as amostras de teste e assim verificar quanto ele acerta com amostras que ainda não foram apresentadas. Para isso, utilizaremos o método predict(), que retorna os valores previstos, e a métrica de acurácia:"
      ],
      "metadata": {
        "id": "lPH5rN68WvCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_previsto = nb.predict(X_teste.values)\n",
        "accuracy_score(y_teste, y_previsto)"
      ],
      "metadata": {
        "id": "psVFszslWYj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Essa pontuação nos diz que o modelo tem um acerto de 100% para os dados de teste.\n",
        "\n",
        "Vamos visualizar essa classificação através de um gráfico:"
      ],
      "metadata": {
        "id": "fdf1Mu1NXx4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.plotting import plot_decision_regions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (10,8))\n",
        "\n",
        "ax = plot_decision_regions(X.values, y, clf=nb, legend=2, X_highlight=X_teste.values)\n",
        "\n",
        "# Adding axes annotations\n",
        "plt.xlabel('comprimento da pétala [cm]')\n",
        "plt.ylabel('largura da pétala [cm]')\n",
        "plt.title('Naïve Bayes')\n",
        "handles, labels = ax.get_legend_handles_labels()\n",
        "ax.legend(handles, \n",
        "          ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], \n",
        "           framealpha=0.3, scatterpoints=1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RbEwLahaXlBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Através da figura acima, é possível verificar as fronteiras de decisão geradas pelo modelo. \n",
        "\n",
        "Para a classe Iris-setosa, todos os exemplos foram classificados corretamente. Entretando algumas das amostras das classes Iris-versicolor e Iris-virginica foram incorretamente classificadas porque o modelo não conseguiu criar uma fronteira de decisão que separa esses pontos.\n",
        "\n",
        "Vamos analisar essa classificação com uma matriz de confusão. Ela é capaz de informar quantas amostras do conjunto foram corretamente associadas ao rótulo real:"
      ],
      "metadata": {
        "id": "aEUdpHXobeOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "\n",
        "y_previsto = nb.predict(X.values)\n",
        "cm = confusion_matrix(y, y_previsto)\n",
        "\n",
        "plt.figure(figsize = (8,6))\n",
        "\n",
        "sn.heatmap(cm, \n",
        "           annot=True, \n",
        "           cmap= 'winter_r', \n",
        "           xticklabels = ['Iris-setosa','Iris-versicolor','Iris-virginica'],\n",
        "           yticklabels = ['Iris-setosa','Iris-versicolor','Iris-virginica'],\n",
        "           cbar=False)\n",
        "plt.xlabel('Classe prevista')\n",
        "plt.ylabel('Classe real')\n",
        "plt.title('Matriz de confusão - Naïve Bayes')"
      ],
      "metadata": {
        "id": "U7pSbKczYfdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Através da matriz de confusão, podemos notar que o modelo classifica incorretamente 3 amostras para cada classe de Iris-versicolor e Iris-virginica. \n",
        "\n",
        "Isso mostra que, apesar de obter uma boa acurácia, o modelo não consegue acertar totalmente. Para nosso exemplo isso não é exatamente um problema, mas em aplicações reais, errar a identificação de uma determinada classe pode não ser tolerado para a finalidade pretendida. Nesses casos, pode ser necessário reavaliar o modelo que foi empregado, afim de encontrar um que se ajuste melhor aos dados, ou ainda buscar por melhores representações do dado para o contexto."
      ],
      "metadata": {
        "id": "1rfTJDQpg5YR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criando um modelo de agrupamento"
      ],
      "metadata": {
        "id": "nvELY81Rqr_k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A partir de agora, utilizaremos o mesmo conjunto de dados porém iremos empregar uma tarefa de aprendizado não supervisionado, o agrupamento.\n",
        "\n",
        "O agrupamento é realizado quando não temos o rótulo das classes do conjunto de dados. No nosso caso, o conjunto Iris possui os rótulos de cada amostra. Vamos utilizar esses rótulos apenas como uma forma de validação do exemplo. O modelo irá aprender sem receber a informação dos rótulos.\n",
        "\n",
        "Para isso, utilizaremos o algoritmo K-médias. K-médias é um algoritmo baseado em centróides, ou um algoritmo baseado em distância, onde calculamos as distâncias para atribuir uma amostra a um grupo. No K-médias, cada grupo está associado a um centroide.\n",
        "\n",
        "Em termos gerais, o algoritmo faz o seguinte:\n",
        "\n",
        "\n",
        "1.   Escolha o número de grupos k\n",
        "2.   Selecione k amostras aleatórias dos dados como centroides\n",
        "3.   Atribua todas as amostras ao centróide do grupo mais próximo\n",
        "4.   Recalcule os centróides dos grupos recém-formados     \n",
        "5.   Repita os passos 3 e 4"
      ],
      "metadata": {
        "id": "oFiEnmdLrelE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mas como definir os k grupos?"
      ],
      "metadata": {
        "id": "zeeGjkrYvBas"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O número de grupos pode ser um chute. Mas existem formas de encontrar um valor k que seja próximo do ideal. Uma das técnicas mais utilizadas é a técnica do cotovelo.\n",
        "\n",
        "A ideia é treinar vários modelos do K-médias com valores diferentes de k. Depois, gerar um gráfico mostrando o valor de inércia do modelo pelo número de k. A inércia é a soma das distâncias quadradas das amostras até o centro do grupo mais próximo. \n",
        "\n",
        "Aqueles valores no \"cotovelo\" do gráfico são possivelmente os melhores valores de k.\n",
        "\n",
        "Vamos ver a seguir essa abordagem:"
      ],
      "metadata": {
        "id": "xs5sCsOqvIfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "vetor_inercia = []\n",
        "\n",
        "for i in range(1, 11):\n",
        "    kmedias = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 42)\n",
        "    kmedias.fit(X)\n",
        "    vetor_inercia.append(kmedias.inertia_)\n",
        "\n",
        "plt.figure(figsize = (8,6)) \n",
        "plt.plot(range(1, 11), vetor_inercia)\n",
        "plt.title('O método do cotovelo')\n",
        "plt.xlabel('Nº de grupos')\n",
        "plt.ylabel('Inércia')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-JwgsW8QeGEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pelo gráfico, vemos que os melhores valores possíveis para o modelo seriam 2 ou 3. Já temos o conhecimento de que o nosso conjunto possui 3 classes diferentes, por isso usaremos k=3. Se estivessemos lidando com um problema desconhecido, poderiamos testar k=2 e k=3 para avaliarmos qual valor de k produziria grupos mais adequados."
      ],
      "metadata": {
        "id": "C0KWSFTiyEuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agrupando com o K-médias"
      ],
      "metadata": {
        "id": "khCsa8t2yrl_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos então gerar nosso modelo de agrupamento com valor de k = 3."
      ],
      "metadata": {
        "id": "HJPPMWeVyuZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmedias = KMeans(n_clusters = 3, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 42)\n",
        "y_kmedias = kmedias.fit_predict(X)\n",
        "y_kmedias"
      ],
      "metadata": {
        "id": "oyOoXw5Bxtmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora, temos um valor de grupo associado a cada amostra do nosso conjunto de dados. Vamos visualizar as amostras e os respectivos grupos/centroides definidos pelo modelo:"
      ],
      "metadata": {
        "id": "CvtSppC7zWkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (8,6))\n",
        "plt.scatter(X[y_kmedias == 0][\"comprimento_petala\"], X[y_kmedias == 0][\"largura_petala\"], s = 100, c = 'green', label='0')\n",
        "plt.scatter(X[y_kmedias == 1][\"comprimento_petala\"], X[y_kmedias == 1][\"largura_petala\"], s = 100, c = 'blue', label='1')\n",
        "plt.scatter(X[y_kmedias == 2][\"comprimento_petala\"], X[y_kmedias == 2][\"largura_petala\"], s = 100, c = 'orange', label='2')\n",
        "\n",
        "# Centro dos grupos\n",
        "plt.scatter(kmedias.cluster_centers_[:, 0], kmedias.cluster_centers_[:,1], s = 100, c = 'red', label = 'Centroides')\n",
        "\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "FCaoZRs4zWDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como sabemos as classes do nosso problema, podemos rotular cada grupo gerado com os nomes dessas classes, sendo que o grupo rotulado como 0 é a classe Iris-virginica, o grupo 1 representa a classe de Iris-setosa e o grupo 2 as flores Iris-versicolor:"
      ],
      "metadata": {
        "id": "jl1jDm5w2yZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (8,6))\n",
        "plt.scatter(X[y_kmedias == 0][\"comprimento_petala\"], X[y_kmedias == 0][\"largura_petala\"], s = 100, c = 'green', label='Iris-virginica')\n",
        "plt.scatter(X[y_kmedias == 1][\"comprimento_petala\"], X[y_kmedias == 1][\"largura_petala\"], s = 100, c = 'blue', label='Iris-setosa')\n",
        "plt.scatter(X[y_kmedias == 2][\"comprimento_petala\"], X[y_kmedias == 2][\"largura_petala\"], s = 100, c = 'orange', label='Iris-versicolor')\n",
        "\n",
        "# Centro dos grupos\n",
        "plt.scatter(kmedias.cluster_centers_[:, 0], kmedias.cluster_centers_[:,1], s = 100, c = 'red', label = 'Centroides')\n",
        "\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "SKbMzyWJ0Er5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesse exemplo, conseguimos também comparar quais os \"grupos\" originais com os grupos encontrados pelo modelo:"
      ],
      "metadata": {
        "id": "ti4ISjz63se4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(8,10))\n",
        "\n",
        "ax[0].scatter(X['comprimento_petala'], X['largura_petala'], c=y, cmap=ListedColormap(['blue', 'orange', 'green']))\n",
        "ax[0].title.set_text('Classes verdadeiras')\n",
        "ax[1].scatter(X['comprimento_petala'], X['largura_petala'], c=y_kmedias, cmap=ListedColormap(['green', 'blue', 'orange']))\n",
        "ax[1].title.set_text('Previsões K-médias')"
      ],
      "metadata": {
        "id": "F-8f5EAr0FF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Diferente da classificação, no agrupamento não existe uma forma de medir o quanto o modelo acerta ou erra, dado que o valor de classe real não existe. No entanto, é possível empregar medidas que avaliam quão bem formados os grupos estão. Essas medidas avaliam, por exemplo, quão próxima uma amostra está das outras amostras associadas a um mesmo grupo e quão distante ela está das amostras de um outro grupo."
      ],
      "metadata": {
        "id": "wDsHYv-86gID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aprendizado Supervisionado com Redes Neurais"
      ],
      "metadata": {
        "id": "7U_phfj19w--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos realizar a tarefa de classificação dos dados do conjunto Iris, mas agora empregando uma rede neural, mais especificamente um Perceptron Multicamadas (MLP)."
      ],
      "metadata": {
        "id": "knluFhfw9425"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ajustando os dados"
      ],
      "metadata": {
        "id": "D3LlCooLJu06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Redes Neurais são muito suscetíveis aos valores de entrada da rede. Caso eles estejam em escalas muito diferentes, a rede terá problemas para conseguir classificar os dados. Sendo assim, antes de empregar o MLP, teremos que aplicar uma padronização nos dados de entrada:"
      ],
      "metadata": {
        "id": "Y3yXxW9DJyLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "sc.fit(X_treino)\n",
        "X_treino_padronizado = sc.transform(X_treino)\n",
        "X_teste_padronizado = sc.transform(X_teste)\n",
        "\n",
        "plt.figure(figsize = (8,6))\n",
        "plt.scatter(X_treino_padronizado[:, 0], X_treino_padronizado[:, 1], c=y_treino, cmap=ListedColormap(['blue', 'orange', 'green']))\n",
        "plt.scatter(X_teste_padronizado[:, 0], X_teste_padronizado[:, 1], c=y_teste, cmap=ListedColormap(['blue', 'orange', 'green']))"
      ],
      "metadata": {
        "id": "ASNwrCGL92Vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treinando e avaliando o modelo"
      ],
      "metadata": {
        "id": "thuz5aubJ1AZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com os dados já padronizados, podemos treinar o MLP. \n",
        "\n",
        "Esse é um modelo que aceita um grande número de parâmetros de configuração (23, para ser mais exato na implementação da sci-kit). Esses parâmetros também são conhecidos como hiperparâmetros, pois influenciam o processo de aprendizado da rede.\n",
        "\n",
        "O objetivo do nosso exemplo é mostrar o funcionamento da rede com um conjunto simples de dados, portanto não vamos nos prender nos detalhes dos hiperparâmetros (existe uma linha de pesquisa só para isso). \n",
        "\n",
        "No nosso caso, vamos configurar o parâmetro que define a taxa de aprendizagem do modelo, o alfa (`alhpa`), e o parâmetro `solver`, que define qual algoritmo será empregado na atualização dos pesos da rede. O parâmetro random_state define apenas uma forma de controlar o experimento (para que todos nós possamos obter resultados parecidos):"
      ],
      "metadata": {
        "id": "R4BIVm8GB9Ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, random_state=42)\n",
        "mlp.fit(X_treino_padronizado, y_treino)\n",
        "y_previsto_mlp = mlp.predict(X_teste_padronizado)\n",
        "accuracy_score(y_teste, y_previsto_mlp)"
      ],
      "metadata": {
        "id": "k1TUyiNkBiu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A acurácia do MLP com os dados de teste é de 96%. \n",
        "\n",
        "Podemos gerar os gráficos com as fronteiras de decisão geradas pelo MLP, bem como a matriz de confusão: "
      ],
      "metadata": {
        "id": "ZvDc1vYSDMd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,8))\n",
        "ax = plot_decision_regions(sc.transform(X), y, clf=mlp, legend=2,\n",
        "                           X_highlight=X_teste_padronizado)\n",
        "\n",
        "\n",
        "plt.xlabel('comprimento da pétala [cm]')\n",
        "plt.ylabel('largura da pétala [cm]')\n",
        "plt.title('MLP')\n",
        "ax.legend(handles, \n",
        "          ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], \n",
        "           framealpha=0.3, scatterpoints=1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xb4-hKmACUjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_previsto = mlp.predict(sc.transform(X))\n",
        "cm = confusion_matrix(y, y_previsto)\n",
        "\n",
        "plt.figure(figsize = (8,6))\n",
        "\n",
        "sn.heatmap(cm, \n",
        "           annot=True, \n",
        "           cmap= 'winter_r', \n",
        "           xticklabels = ['Iris-setosa','Iris-versicolor','Iris-virginica'],\n",
        "           yticklabels = ['Iris-setosa','Iris-versicolor','Iris-virginica'],\n",
        "           cbar=False)\n",
        "plt.xlabel('Classe prevista')\n",
        "plt.ylabel('Classe real')\n",
        "plt.title('Matriz de confusão - MLP')"
      ],
      "metadata": {
        "id": "GfvveKg_Cz_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos notar que as fronteiras de decisão geradas pelo MLP são diferentes daquelas geradas pelo Naïve Bayes. Isso se deve ao funcionamento do modelo, que tenta traçar diferentes retas no hiperplano no qual os dados estão espacialmente distribuídos. Dessa forma, ele consegue gerar fronteiras de decisão mais elaboradas e, por consequência, diferenciar completamente as classes de flores Iris-setosa e Iris-virginica. \n",
        "\n",
        "Ainda assim, o modelo não consegue separar totalmente os exemplos da classe Iris-versicolor, como podemos perceber pela matriz de confusão."
      ],
      "metadata": {
        "id": "bq4LWHBdFnrF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aprendizado Não Supervisionado com Redes Neurais"
      ],
      "metadata": {
        "id": "a9VR81BqJp4T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podmeos empregar um mapa auto-organizável (SOM) para realizar o agrupamento dos dados do conjunto Iris. Entretanto, o SOM não existe na biblioteca padrão da scikit-learn.\n",
        "\n",
        "Utilizaremos uma biblioteca desenvolvida nos padrões da sklearn que disponibiliza uma implementação do modelo SOM:"
      ],
      "metadata": {
        "id": "40vOt7QIKOuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn-som"
      ],
      "metadata": {
        "id": "JuJl8SflD9j1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora que temos a biblioteca, vamos criar o modelo.\n",
        "\n",
        "Como parâmetros desse algoritmo, temos `m` e `n`, que definem a matriz de representação do mapa, ou seja, a quantidade de neurônios. Definimos também o valor de `dim`, que nos diz quantas dimensões tem os dados de entrada, ou seja, a quantidade de atributos. Por fim, configuramos o `sigma`, que é a taxa de aprendizado empregada na atualização dos pesos do SOM. O parâmetro random_state define apenas uma forma de controlar o experimento (para que todos nós possamos obter resultados parecidos): "
      ],
      "metadata": {
        "id": "TzgJ-g52Mslf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn_som.som import SOM\n",
        "som = SOM(m=3, n=1, dim=2, sigma=0.6, random_state=42)\n",
        "som.fit(X.values)\n",
        "y_som = som.predict(X.values)\n",
        "\n",
        "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(8,10))\n",
        "\n",
        "ax[0].scatter(X.values[:, 0], X.values[:, 1], c=y, cmap=ListedColormap(['blue', 'orange', 'green']))\n",
        "ax[0].title.set_text('Classes verdadeiras')\n",
        "ax[1].scatter(X.values[:, 0], X.values[:, 1], c=y_som, cmap=ListedColormap(['orange', 'green', 'blue']))\n",
        "ax[1].title.set_text('Previsões SOM')"
      ],
      "metadata": {
        "id": "eGtmh1MSMqEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fontes:"
      ],
      "metadata": {
        "id": "yAMKfGrkWXRe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. [GaussianNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)\n",
        "2. [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\n",
        "3. [MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)\n",
        "4. [sklearn-som](https://pypi.org/project/sklearn-som/)"
      ],
      "metadata": {
        "id": "-5pwfknlWZdT"
      }
    }
  ]
}